%PATRICIA MONICA GEORGE
%PATTERN RECOGNITION
%BAYESIAN CLASSIFIER

N=15000;
DIMENSION=4;
for i=1:5000
    C1_H1(i)=H1(i);
    C1_H2(i)=H2(i);
    C1_H3(i)=H3(i);
    C1_H4(i)=H4(i);    
    C2_H1(i)=H1(i+5000);
    C2_H2(i)=H2(i+5000);
    C2_H3(i)=H3(i+5000);
    C2_H4(i)=H4(i+5000); 
    C3_H1(i)=H1(i+10000);
    C3_H2(i)=H2(i+10000);
    C3_H3(i)=H3(i+10000);
    C3_H4(i)=H4(i+10000); 
end

C1=[C1_H1' C1_H2' C1_H3' C1_H4'];
C2=[C2_H1' C2_H2' C2_H3' C2_H4'];
C3=[C3_H1' C3_H2' C3_H3' C3_H4'];

% FINDING MEAN FOR EACH CLASS
MEAN_C1=[mean(C1_H1);mean(C1_H2);mean(C1_H3);mean(C1_H4)];
MEAN_C2=[mean(C2_H1);mean(C2_H2);mean(C2_H3);mean(C2_H4)];
MEAN_C3=[mean(C3_H1);mean(C3_H2);mean(C3_H3);mean(C3_H4)];

% FINDING COVARIANCE FOR EACH CLASS
COVARIANCE_C1=cov(C1);
COVARIANCE_C2=cov(C2);
COVARIANCE_C3=cov(C3);

%TRAINING AND CLASSIFYING THE TRAINING DATA USING A DISCRIMINANT FUNCTION
for i=1:15000
    TEST_DATA=[H1(i);H2(i);H3(i);H4(i)];
    DISCRIMINANT_FUNCTION_C1=(-(1/2)*(TEST_DATA-MEAN_C1)'*inv(COVARIANCE_C1)*(TEST_DATA-MEAN_C1))-((DIMENSION/2)*log(2*pi))-((1/2)*log(det(COVARIANCE_C1)));
    DISCRIMINANT_FUNCTION_C2=(-(1/2)*(TEST_DATA-MEAN_C2)'*inv(COVARIANCE_C2)*(TEST_DATA-MEAN_C2))-((DIMENSION/2)*log(2*pi))-((1/2)*log(det(COVARIANCE_C2)));
    DISCRIMINANT_FUNCTION_C3=(-(1/2)*(TEST_DATA-MEAN_C3)'*inv(COVARIANCE_C3)*(TEST_DATA-MEAN_C3))-((DIMENSION/2)*log(2*pi))-((1/2)*log(det(COVARIANCE_C3)));
    
     if((DISCRIMINANT_FUNCTION_C1>DISCRIMINANT_FUNCTION_C2)&&(DISCRIMINANT_FUNCTION_C1>DISCRIMINANT_FUNCTION_C3))
            CLASS_H(i)=1;
    end
    if((DISCRIMINANT_FUNCTION_C2>DISCRIMINANT_FUNCTION_C1)&&(DISCRIMINANT_FUNCTION_C2>DISCRIMINANT_FUNCTION_C3))
            CLASS_H(i)=2;
    end
    if((DISCRIMINANT_FUNCTION_C3>DISCRIMINANT_FUNCTION_C1)&&(DISCRIMINANT_FUNCTION_C3>DISCRIMINANT_FUNCTION_C2))
            CLASS_H(i)=3;
    end
end

%CALCULATING PROBABILITY OF ERROR FOR THE CLASSIFIED TRAINING DATA
R11=0;R22=0;R33=0;
W12=0;W21=0;W31=0;W13=0;W23=0;W32=0;
for i=1:5000
    if(CLASS_H(i)==1)
        R11=R11+1;
    else if(CLASS_H(i)==2)
        W12=W12+1;
        else if(CLASS_H(i)==3)
               W13=W13+1; 
            end
        end
    end
end
for i=5001:10000
   if(CLASS_H(i)==1)
        W21=W21+1;
    else if(CLASS_H(i)==2)
        R22=R22+1;
        else if(CLASS_H(i)==3)
               W23=W23+1; 
            end
        end
    end
end
for i=10001:15000
   if(CLASS_H(i)==1)
        W31=W31+1;
    else if(CLASS_H(i)==2)
        W32=W32+1;
        else if(CLASS_H(i)==3)
               R33=R33+1; 
            end
        end
    end
end

RIGHT_H=R11+R22+R33;
WRONG_H=W12+W21+W13+W31+W23+W32;
PROBABILTY_OF_ERROR_H=WRONG_H/N

%CONFUSION MATRIX FOR THE CLASSIFIED TRAINING DATA
CONFUSION_MATRIX_H=[R11 W12 W13;W21 R22 W23; W31 W32 R33]

%TRAINING AND CLASSIFYING THE TEST DATA USING A DISCRIMINANT FUNCTION
for i=1:15000
    TEST_DATA=[T1(i);T2(i);T3(i);T4(i)];
    DISCRIMINANT_FUNCTION_C1=(-(1/2)*(TEST_DATA-MEAN_C1)'*inv(COVARIANCE_C1)*(TEST_DATA-MEAN_C1))-((DIMENSION/2)*log(2*pi))-((1/2)*log(det(COVARIANCE_C1)));
    DISCRIMINANT_FUNCTION_C2=(-(1/2)*(TEST_DATA-MEAN_C2)'*inv(COVARIANCE_C2)*(TEST_DATA-MEAN_C2))-((DIMENSION/2)*log(2*pi))-((1/2)*log(det(COVARIANCE_C2)));
    DISCRIMINANT_FUNCTION_C3=(-(1/2)*(TEST_DATA-MEAN_C3)'*inv(COVARIANCE_C3)*(TEST_DATA-MEAN_C3))-((DIMENSION/2)*log(2*pi))-((1/2)*log(det(COVARIANCE_C3)));
    
     if((DISCRIMINANT_FUNCTION_C1>DISCRIMINANT_FUNCTION_C2)&&(DISCRIMINANT_FUNCTION_C1>DISCRIMINANT_FUNCTION_C3))
            CLASS_T(i)=1;
    end
    if((DISCRIMINANT_FUNCTION_C2>DISCRIMINANT_FUNCTION_C1)&&(DISCRIMINANT_FUNCTION_C2>DISCRIMINANT_FUNCTION_C3))
            CLASS_T(i)=2;
    end
    if((DISCRIMINANT_FUNCTION_C3>DISCRIMINANT_FUNCTION_C1)&&(DISCRIMINANT_FUNCTION_C3>DISCRIMINANT_FUNCTION_C2))
            CLASS_T(i)=3;
    end
end

%CALCULATING PROBABILITY OF ERROR FOR THE CLASSIFIED TRAINING DATA
R11=0;R22=0;R33=0;
W12=0;W21=0;W31=0;W13=0;W23=0;W32=0;
i=1;
while i<N
    if(CLASS_T(i)==1 && i<N)
              W21=W21+1;
    else if(CLASS_T(i)==2 && i<N)
            R22=R22+1;
        else if(CLASS_T(i)==3 && i<N)
               W23=W23+1; 
            end
        end
    end
     i=i+1;
    if(CLASS_T(i)==1 && i<N)
              W31=W31+1;
    else if(CLASS_T(i)==2 && i<N)
            W32=W32+1;
        else if(CLASS_T(i)==3 && i<N)
               R33=R33+1; 
            end
        end
    end
     i=i+1;
    if(CLASS_T(i)==1 && i<N)
             R11=R11+1;
    else if(CLASS_T(i)==2 && i<N)
            W12=W12+1;
        else if(CLASS_T(i)==3 && i<N)
               W13=W13+1; 
            end
        end
    end
     i=i+1;
  if(CLASS_T(i)==1 && i<N)
              W31=W31+1;
    else if(CLASS_T(i)==2 && i<N)
            W32=W32+1;
        else if(CLASS_T(i)==3 && i<N)
               R33=R33+1; 
            end
        end
  end
   i=i+1;
     if(CLASS_T(i)==1 && i<N)
             R11=R11+1;
    else if(CLASS_T(i)==2 && i<N)
            W12=W12+1;
        else if(CLASS_T(i)==3 && i<N)
               W13=W13+1; 
            end
        end
     end
      i=i+1;
     if(CLASS_T(i)==1 && i<N)
              W21=W21+1;
    else if(CLASS_T(i)==2 && i<N)
            R22=R22+1;
        else if(CLASS_T(i)==3 && i<N)
               W23=W23+1; 
            end
        end
    end
    i=i+1;
end
RIGHT_T=R11+R22+R33;
WRONG_T=W12+W13+W21+W23+W31+W32;
PROBABILITY_OF_ERROR_T=WRONG_T/N

%CONFUSION MATRIX FOR THE CLASSIFIED TEST DATA
CONFUSION_MATRIX_T=[R11 W12 W13; W21 R22 W23; W31 W32 R33]
